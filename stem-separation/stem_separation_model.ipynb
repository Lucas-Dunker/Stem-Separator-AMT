{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nussl\n",
    "!pip install git+https://github.com/source-separation/tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from common import data, viz\n",
    "import nussl\n",
    "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.26it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.29it/s]\n",
      "100%|██████████| 50/50 [00:15<00:00,  3.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare MUSDB\n",
    "data.prepare_musdb('~/.nussl/tutorial/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "fg_path = \"~/.nussl/tutorial/train\"\n",
    "train_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=1000, coherent_prob=1.0)\n",
    "\n",
    "item = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_path = \"~/.nussl/tutorial/valid\"\n",
    "val_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=500)\n",
    "\n",
    "fg_path = \"~/.nussl/tutorial/test\"\n",
    "test_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix AudioSignal (unlabeled): 5.000 sec @ path unknown, 44100 Hz, 1 ch. <class 'nussl.core.audio_signal.AudioSignal'>\n",
      "sources {'vocals': <nussl.core.audio_signal.AudioSignal object at 0x30a84a5c0>, 'drums': <nussl.core.audio_signal.AudioSignal object at 0x30a8e0fd0>, 'bass': <nussl.core.audio_signal.AudioSignal object at 0x30a8e0460>, 'other': <nussl.core.audio_signal.AudioSignal object at 0x30a8e1180>} <class 'dict'>\n",
      "metadata {'jam': <JAMS(file_metadata=<FileMetadata(...)>,\n",
      "      annotations=[1 annotation],\n",
      "      sandbox=<Sandbox(...)>)>, 'idx': 0} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for key in item:\n",
    "    print(key, item[key], type(item[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemSeparationModel(nn.Module):\n",
    "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
    "                 num_layers, bidirectional, dropout, num_sources, \n",
    "                activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.verbose = False\n",
    "\n",
    "        self.amplitude_to_db = AmplitudeToDB()\n",
    "        self.input_normalization = BatchNorm(num_features)\n",
    "        self.recurrent_stack = RecurrentStack(\n",
    "            num_features * num_audio_channels, hidden_size, \n",
    "            num_layers, bool(bidirectional), dropout\n",
    "        )\n",
    "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
    "        self.embedding = Embedding(num_features, hidden_size, \n",
    "                                   num_sources, activation, \n",
    "                                   num_audio_channels)\n",
    "        \n",
    "    def forward(self, item):\n",
    "        # Get magnitude of mixture signal\n",
    "        mixture_magnitude_np = np.abs(item['mix'].stft())\n",
    "        mixture_magnitude = torch.tensor(mixture_magnitude_np).float()\n",
    "        self.log(f\"mixture_magnitude shape before batch dimension: {mixture_magnitude.shape}\")\n",
    "\n",
    "        # Add batch dimension if needed and reshape\n",
    "        # Expected shape: (batch_size, freq_bins, time_steps)\n",
    "        # mixture_magnitude shape: [1, 257, 1724]\n",
    "        if mixture_magnitude.dim() == 3 and mixture_magnitude.size(-1) == 1:\n",
    "            mixture_magnitude = mixture_magnitude.squeeze(-1)  # Remove last dimension of size 1\n",
    "        if mixture_magnitude.dim() == 2:\n",
    "            mixture_magnitude = mixture_magnitude.unsqueeze(0)  # Add batch dimension\n",
    "        self.log(f\"mixture_magnitude shape after batch dimension: {mixture_magnitude.shape}\")\n",
    "\n",
    "        # Convert to log amplitude\n",
    "        mixture_log_amplitude = self.amplitude_to_db(mixture_magnitude)\n",
    "        self.log(f\"Shape after amplitude to db: {mixture_log_amplitude.shape}\")\n",
    "        \n",
    "        # Normalize the data\n",
    "        normalized = self.input_normalization(mixture_log_amplitude)\n",
    "        self.log(f\"Shape after normalization: {normalized.shape}\")\n",
    "    \n",
    "        # Reshape for LSTM: (batch, time_steps, freq_bins)\n",
    "        normalized = normalized.transpose(1, 2)\n",
    "        self.log(f\"Shape before LSTM (after transpose): {normalized.shape}\")\n",
    "\n",
    "        # Pass through LSTM\n",
    "        output = self.recurrent_stack(normalized)\n",
    "        self.log(f\"Shape after LSTM: {output.shape}\")\n",
    "\n",
    "        # Generate mask - should have shape (batch, time_steps, freq_bins, num_sources)\n",
    "        # mask shape: (1, 1724, 257, 1)\n",
    "        mask = self.embedding(output)\n",
    "        if mask.dim() == 5:\n",
    "            mask = mask.squeeze(-1)  # Remove the extra dimension from the mask if it exists\n",
    "        self.log(f\"Shape of mask: {mask.shape}\")\n",
    " \n",
    "        # Reshape mixture_magnitude to align with mask dimensions\n",
    "        # Current shape: (1, 257, 1724) -> Need: (1, 1724, 257, 1)\n",
    "        mixture_magnitude = mixture_magnitude.transpose(1, 2)  # (1, 1724, 257)\n",
    "        mixture_magnitude = mixture_magnitude.unsqueeze(-1)    # (1, 1724, 257, 1)\n",
    "        self.log(f\"Shape of reshaped mixture_magnitude: {mixture_magnitude.shape}\")\n",
    "    \n",
    "        # Apply mask to get estimates\n",
    "        estimates = mixture_magnitude * mask\n",
    "        self.log(f\"Shape of estimates: {estimates.shape}\")\n",
    "\n",
    "        return {\n",
    "            'mask': mask,\n",
    "            'estimates': estimates,\n",
    "        }\n",
    "\n",
    "    def log(self, s):\n",
    "        if self.verbose:\n",
    "            print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = stft_params.window_length // 2 + 1\n",
    "num_audio_channels = 1\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.3\n",
    "num_sources = 1\n",
    "activation = 'sigmoid'\n",
    "\n",
    "model = StemSeparationModel(\n",
    "    num_features=num_features,\n",
    "    num_audio_channels=num_audio_channels,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    dropout=dropout,\n",
    "    num_sources=num_sources,\n",
    "    activation=activation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixture_magnitude shape before batch dimension: torch.Size([257, 1724, 1])\n",
      "mixture_magnitude shape after batch dimension: torch.Size([1, 257, 1724])\n",
      "Shape after amplitude to db: torch.Size([1, 257, 1724])\n",
      "Shape after normalization: torch.Size([1, 257, 1724])\n",
      "Shape before LSTM (after transpose): torch.Size([1, 1724, 257])\n",
      "Shape after LSTM: torch.Size([1, 1724, 100])\n",
      "Shape of mask: torch.Size([1, 1724, 257, 1])\n",
      "Shape of reshaped mixture_magnitude: torch.Size([1, 1724, 257, 1])\n",
      "Shape of estimates: torch.Size([1, 1724, 257, 1])\n",
      "\n",
      "mask <class 'torch.Tensor'> torch.Size([1, 1724, 257, 1])\n",
      "estimates <class 'torch.Tensor'> torch.Size([1, 1724, 257, 1])\n"
     ]
    }
   ],
   "source": [
    "model.verbose = True\n",
    "\n",
    "def process_item(model, item):\n",
    "    with torch.no_grad():\n",
    "        output = model(item)\n",
    "    return output\n",
    "\n",
    "output = process_item(model, item)\n",
    "print()\n",
    "for key in output:\n",
    "    print(key, type(output[key]), output[key].shape)\n",
    "\n",
    "model.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stem-separation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
