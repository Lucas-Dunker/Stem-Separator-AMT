{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nussl\n",
    "!pip install git+https://github.com/source-separation/tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from common import data, utils, viz\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import argbind\n",
    "from pathlib import Path\n",
    "\n",
    "import nussl\n",
    "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.23it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.24it/s]\n",
      "100%|██████████| 50/50 [00:15<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare MUSDB\n",
    "data.prepare_musdb('~/.nussl/tutorial/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),  # TODO: currently trying to output only the vocals source from the model\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"~/.nussl/tutorial/train\"\n",
    "val_folder = \"~/.nussl/tutorial/valid\"\n",
    "\n",
    "MAX_MIXTURES = int(1e8) # Set to some impossibly high number for on-the-fly mixing.\n",
    "\n",
    "train_data = data.on_the_fly(stft_params, transform=tfm, fg_path=train_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, num_workers=1, batch_size=10)\n",
    "\n",
    "val_data = data.on_the_fly(stft_params, transform=tfm, fg_path=val_folder, num_mixtures=10, coherent_prob=1.0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, num_workers=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index <class 'int'> \n",
      "mix_magnitude <class 'torch.Tensor'> torch.Size([1724, 257, 1])\n",
      "ideal_binary_mask <class 'torch.Tensor'> torch.Size([1724, 257, 1, 2])\n",
      "source_magnitudes <class 'torch.Tensor'> torch.Size([1724, 257, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "item = train_data[0]\n",
    "for key in item:\n",
    "    print(key, type(item[key]), item[key].shape if isinstance(item[key], torch.Tensor) else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),  # TODO: currently trying to extract only the vocals source\n",
    "])\n",
    "\n",
    "test_folder = \"~/.nussl/tutorial/test\"\n",
    "test_data = data.on_the_fly(stft_params, transform=test_tfm, fg_path=test_folder, num_mixtures=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copied from https://github.com/nussl/nussl/blob/master/nussl/ml/networks/separation_model.py\n",
    "\n",
    "\n",
    "def _remove_cache_from_tfms(transforms):\n",
    "    \"\"\"Helper function to remove cache from transforms.\n",
    "    \"\"\"\n",
    "    transforms = copy.deepcopy(transforms)\n",
    "\n",
    "    if isinstance(transforms, nusssl.datasets.transforms.Compose):\n",
    "        for t in transforms.transforms:\n",
    "            if isinstance(t, nussl.datasets.transforms.Cache):\n",
    "                transforms.transforms.remove(t)\n",
    "\n",
    "    return transforms\n",
    "\n",
    "\n",
    "def _prep_metadata(metadata):\n",
    "    \"\"\"Helper function for preparing metadata before saving a model.\n",
    "    \"\"\"\n",
    "    metadata = copy.deepcopy(metadata)\n",
    "    if 'transforms' in metadata:\n",
    "        metadata['transforms'] = _remove_cache_from_tfms(metadata['transforms'])\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemSeparationModel(nn.Module):\n",
    "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
    "                 num_layers, bidirectional, dropout, num_sources, \n",
    "                activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.verbose = False\n",
    "\n",
    "        self.amplitude_to_db = AmplitudeToDB()\n",
    "        self.input_normalization = BatchNorm(num_features)\n",
    "        self.recurrent_stack = RecurrentStack(\n",
    "            num_features * num_audio_channels, hidden_size, \n",
    "            num_layers, bool(bidirectional), dropout\n",
    "        )\n",
    "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
    "        self.embedding = Embedding(num_features, hidden_size, \n",
    "                                   num_sources, activation, \n",
    "                                   num_audio_channels)\n",
    "        \n",
    "        self.set_up_config(num_features, num_audio_channels, hidden_size,\n",
    "                 num_layers, bidirectional, dropout, num_sources, \n",
    "                activation)\n",
    "\n",
    "    def set_up_config(self, num_features, num_audio_channels, hidden_size,\n",
    "                 num_layers, bidirectional, dropout, num_sources, \n",
    "                activation='sigmoid'):\n",
    "        modules = {\n",
    "            'model': {\n",
    "                'class': 'StemSeparationModel',\n",
    "                'args': {\n",
    "                    'num_features': num_features,\n",
    "                    'num_audio_channels': num_audio_channels,\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'num_layers': num_layers,\n",
    "                    'bidirectional': bidirectional,\n",
    "                    'dropout': dropout,\n",
    "                    'num_sources': num_sources,\n",
    "                    'activation': activation,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        connections = [\n",
    "            ['model', ['mix_magnitude']]\n",
    "        ]\n",
    "\n",
    "        for key in ['mask', 'vocal_estimate']:\n",
    "            modules[key] = {'class': 'Alias'}\n",
    "            connections.append([key, [f'model:{key}']])\n",
    "        \n",
    "        output = ['vocal_estimate', 'mask',]\n",
    "        self.config = {\n",
    "            'name': 'StemSeparationModel',\n",
    "            'modules': modules,\n",
    "            'connections': connections,\n",
    "            'output': output,\n",
    "        }\n",
    "        self.metadata = {\n",
    "            'config': self.config,\n",
    "            'nussl_version': '0.0.1',\n",
    "        }\n",
    "\n",
    "    def log(self, s):\n",
    "        if self.verbose:\n",
    "            print(s)\n",
    "\n",
    "    def forward(self, item):\n",
    "        # Get magnitude of mixture signal\n",
    "        mixture_magnitude = item['mix_magnitude']\n",
    "        if mixture_magnitude.dim() == 3:\n",
    "            mixture_magnitude = mixture_magnitude.unsqueeze(0)  # Add a batch dimension to the mixture magnitude if needed\n",
    "        self.log(f\"Shape of mixture_magnitude: {mixture_magnitude.shape}\")\n",
    "\n",
    "        # Convert to log amplitude\n",
    "        mixture_log_amplitude = self.amplitude_to_db(mixture_magnitude)\n",
    "        self.log(f\"Shape after amplitude to db: {mixture_log_amplitude.shape}\")\n",
    "        \n",
    "        # Normalize the data\n",
    "        normalized = self.input_normalization(mixture_log_amplitude)\n",
    "        self.log(f\"Shape after normalization: {normalized.shape}\")\n",
    "\n",
    "        # Pass through LSTM\n",
    "        output = self.recurrent_stack(normalized)\n",
    "        self.log(f\"Shape after LSTM: {output.shape}\")\n",
    "\n",
    "        # Generate mask\n",
    "        mask = self.embedding(output)\n",
    "        self.log(f\"Shape of mask: {mask.shape}\")\n",
    "    \n",
    "        # Apply mask to get estimates\n",
    "        # TODO: right now this model is defined just to output an estimate of the vocals source - later can expand this to calculate a mask for every source\n",
    "        vocals_estimate = mixture_magnitude.unsqueeze(-1) * mask\n",
    "        self.log(f\"Shape of vocals estimate: {vocals_estimate.shape}\")\n",
    "\n",
    "        return {\n",
    "            'mask': mask,\n",
    "            'vocals_estimate': vocals_estimate,\n",
    "        }\n",
    "\n",
    "    # TODO: copied from https://github.com/nussl/nussl/blob/master/nussl/ml/networks/separation_model.py\n",
    "    def save(self, location, metadata=None, train_data=None, \n",
    "             val_data=None, trainer=None):\n",
    "        \"\"\"\n",
    "        Saves a SeparationModel into a location into a dictionary with the\n",
    "        weights and model configuration.\n",
    "        Args:\n",
    "            location: (str) Where you want the model saved, as a path.\n",
    "            metadata: (dict) Additional metadata to save along with the model. By default,\n",
    "                model config and nussl version is saved as metadata.\n",
    "            train_data: (BaseDataset) Dataset used for training. Metadata will be extracted\n",
    "                from this object if it is passed into the save function, and saved \n",
    "                alongside the model.\n",
    "            val_data: (BaseDataset) Dataset used for validation. Metadata will be extracted\n",
    "                from this object if it is passed into the save function, and saved \n",
    "                alongside the model.\n",
    "            trainer: (ignite.Engine) Engine used for training. Metadata will be extracted\n",
    "                from this object if it is passed into the save function, and saved alongside\n",
    "                the model.\n",
    "\n",
    "        Returns:\n",
    "            (str): where the model was saved.\n",
    "\n",
    "        \"\"\"\n",
    "        save_dict = {\n",
    "            'state_dict': self.state_dict(),\n",
    "            'config': json.dumps(self.config)\n",
    "        }\n",
    "\n",
    "        metadata = metadata if metadata else {}\n",
    "        metadata.update(self.metadata)\n",
    "\n",
    "        if train_data is not None:\n",
    "            dataset_metadata = {\n",
    "                'stft_params': train_data.stft_params,\n",
    "                'sample_rate': train_data.sample_rate,\n",
    "                'num_channels': train_data.num_channels,\n",
    "                'train_dataset': _prep_metadata(train_data.metadata),\n",
    "            }\n",
    "            metadata.update(dataset_metadata)\n",
    "\n",
    "        try:\n",
    "            metadata['val_dataset'] = _prep_metadata(val_data.metadata)\n",
    "        except: # pragma: no cover\n",
    "            pass\n",
    "        \n",
    "        if trainer is not None:\n",
    "            train_metadata = {\n",
    "                'trainer.state_dict': {\n",
    "                    'epoch': trainer.state.epoch,\n",
    "                    'epoch_length': trainer.state.epoch_length,\n",
    "                    'max_epochs': trainer.state.max_epochs,\n",
    "                    'output': trainer.state.output,\n",
    "                    'metrics': trainer.state.metrics,\n",
    "                    'seed': trainer.state.seed,\n",
    "                },\n",
    "                'trainer.state.epoch_history': trainer.state.epoch_history,\n",
    "            }\n",
    "            metadata.update(train_metadata)\n",
    "\n",
    "        save_dict = {**save_dict, 'metadata': metadata}\n",
    "        torch.save(save_dict, location)\n",
    "        return location\n",
    "\n",
    "    # TODO: copied from https://github.com/nussl/nussl/blob/master/nussl/ml/networks/separation_model.py\n",
    "    def __repr__(self):\n",
    "        output = super().__repr__()\n",
    "        num_parameters = 0\n",
    "        for p in self.parameters():\n",
    "            if p.requires_grad:\n",
    "                num_parameters += np.cumprod(p.size())[-1]\n",
    "        output += '\\nNumber of parameters: %d' % num_parameters\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = stft_params.window_length // 2 + 1\n",
    "num_audio_channels = 1\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.3\n",
    "num_sources = 1\n",
    "activation = 'sigmoid'\n",
    "\n",
    "model = StemSeparationModel(\n",
    "    num_features=num_features,\n",
    "    num_audio_channels=num_audio_channels,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    dropout=dropout,\n",
    "    num_sources=num_sources,\n",
    "    activation=activation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of mixture_magnitude: torch.Size([1, 1724, 257, 1])\n",
      "Shape after amplitude to db: torch.Size([1, 1724, 257, 1])\n",
      "Shape after normalization: torch.Size([1, 1724, 257, 1])\n",
      "Shape after LSTM: torch.Size([1, 1724, 100])\n",
      "Shape of mask: torch.Size([1, 1724, 257, 1, 1])\n",
      "Shape of vocals estimate: torch.Size([1, 1724, 257, 1, 1])\n",
      "\n",
      "mask <class 'torch.Tensor'> torch.Size([1, 1724, 257, 1, 1])\n",
      "vocals_estimate <class 'torch.Tensor'> torch.Size([1, 1724, 257, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "model.verbose = True\n",
    "\n",
    "def process_item(model, item):\n",
    "    # Convert all tensors in the item dictionary to torch.float32\n",
    "    for key, tensor in item.items():\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            item[key] = tensor.to(torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(item)\n",
    "\n",
    "    return output\n",
    "\n",
    "output = process_item(model, item)\n",
    "print()\n",
    "for key in output:\n",
    "    print(key, type(output[key]), output[key].shape)\n",
    "\n",
    "model.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/stem-separation/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/opt/anaconda3/envs/stem-separation/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 10\n",
       "\tepoch: 1\n",
       "\tepoch_length: 10\n",
       "\tmax_epochs: 1\n",
       "\toutput: <class 'dict'>\n",
       "\tbatch: <class 'dict'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>\n",
       "\tepoch_history: <class 'dict'>\n",
       "\titer_history: <class 'dict'>\n",
       "\tpast_iter_history: <class 'dict'>\n",
       "\tsaved_model_path: /Users/shashankjarmale/Documents/Northeastern/Fall 2024 Semester/CS 5100 Foundations of Artificial Intelligence/Project/Stem-Separator-AMT/stem-separation/checkpoints/best.model.pth\n",
       "\toutput_folder: <class 'pathlib.PosixPath'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.verbose = False\n",
    "\n",
    "utils.logger()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['vocals_estimate'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    \n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    \n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['vocals_estimate'],\n",
    "        batch['source_magnitudes']\n",
    "    )    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(), \n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals\n",
    "\n",
    "# Create the engines\n",
    "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
    "    train_step, val_step, device=DEVICE\n",
    ")\n",
    "\n",
    "# We'll save the output relative to this notebook.\n",
    "output_folder = Path('.').absolute()\n",
    "\n",
    "# Adding handlers from nussl that print out details about model training\n",
    "# run the validation step, and save the models.\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
    "    optimizer, train_data, trainer, val_dataloader, validator)\n",
    "\n",
    "trainer.run(\n",
    "    train_dataloader, \n",
    "    epoch_length=10, \n",
    "    max_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stem-separation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
