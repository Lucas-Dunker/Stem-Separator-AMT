{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample \n",
    "\n",
    "- **A discrete measurement of audio signal's amplitude at specifc moment in time.**\n",
    "- The array y contains these samples where each element in y is a single measurement of the audio signal.\n",
    "\n",
    "## Sampling rate  \n",
    "- **How many samples are captured per second in the audio signal.**\n",
    "- It is usually measured in Hertz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform\n",
    "\n",
    "- **Allows us to decompose signals (sound waves) into basic building blocksâ€”sine waves of different frequencies.**\n",
    "- It transforms a **time domain** signal into a **frequency domain** representation.\n",
    "\n",
    "### Time Domain:\n",
    "- The signal is represented as a **change in amplitude over time**, like the raw audio waveform.\n",
    "\n",
    "### Frequency Domain:\n",
    "- The signal is represented by its **constituent frequencies**, showing how much of each frequency is present in the signal.\n",
    "\n",
    "- [Interactive guide to the Fourier Transform](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/)\n",
    "\n",
    "### Limitation:\n",
    "- The **Fourier Transform loses information about time**: it tells you **what frequencies** are present, but not **when** they occur in the signal.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Short-Time Fourier Transform (STFT)\n",
    "\n",
    "- **Extends the Fourier Transform** to handle signals whose frequency content changes over time by analyzing **small sections (windows)** of the signal at a time.\n",
    "- Instead of analyzing the entire signal at once (like the Fourier Transform), **STFT divides the signal into overlapping windows** of fixed length.\n",
    "- The Fourier Transform is applied to each window separately, capturing both **time** and **frequency** information.\n",
    "- By sliding the window across the signal, **STFT captures how the frequency content changes over time**.\n",
    "\n",
    "### Frequency Bins in STFT:\n",
    "- **Frequencies are evenly spaced**. For example, analyzing frequencies between 0 Hz and 22 kHz, each frequency bin might be spaced by 100 Hz.\n",
    "- All frequencies are treated equally, whether low or high.\n",
    "\n",
    "### Example of Frequency Bins in STFT:\n",
    "- 0 Hz, 100 Hz, 200 Hz, 300 Hz, ... up to 22,000 Hz\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Use Constant-Q Transform (CQT)?\n",
    "\n",
    "- In **CQT**, frequencies are **logarithmically spaced**, meaning the spacing between frequency bins **gets wider as the frequencies get higher**.\n",
    "- This is **how musical notes work**, as each **octave represents a doubling of frequency**.\n",
    "\n",
    "### Example of Frequency Bins in CQT:\n",
    "- 32 Hz (C1), 65 Hz (C2), 130 Hz (C3), 261 Hz (C4), 523 Hz (C5), etc.\n",
    "\n",
    "- The spacing between low frequencies is narrow, but the spacing between high frequencies is wider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set root directory where all track folders are located\n",
    "root_folder = 'Data/babyslakh_16k/babyslakh_16k'\n",
    "\n",
    "def load_audio_and_labels(track_folder):\n",
    "    \"\"\"\n",
    "    Loads audio and corresponding label files from a given track folder.\n",
    "    \n",
    "    Arguments:\n",
    "    - track_folder: Path to the track folder containing .wav and .lab files\n",
    "    \n",
    "    Returns:\n",
    "    - audio_data: List of loaded audio arrays\n",
    "    - sample_rates: List of sample rates corresponding to each audio file\n",
    "    - chord_labels: List of chord annotations for each time step\n",
    "    \"\"\"\n",
    "    audio_data = []\n",
    "    sample_rates = []\n",
    "    chord_labels = []\n",
    "    \n",
    "    # Load all .wav files in the track folder\n",
    "    for file_name in os.listdir(track_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(track_folder, file_name)\n",
    "            y, sr = librosa.load(file_path, sr=None)  # Load audio with original sample rate\n",
    "            audio_data.append(y)\n",
    "            sample_rates.append(sr)\n",
    "    \n",
    "    #  set the label file path based on the track folder name\n",
    "    track_name = os.path.basename(track_folder)  # Track folder name \n",
    "    label_file_name = f\"{track_name}.lab\"  # Label file name \n",
    "    label_path = os.path.join(track_folder, label_file_name)\n",
    "    \n",
    "    # Load .lab file if it exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = []\n",
    "            for line in f:\n",
    "                # Only take the first three values, ignoring any extra ones\n",
    "                values = line.strip().split()[:3]\n",
    "                if len(values) == 3:  # Ensure we have exactly three values\n",
    "                    start, end, chord = values\n",
    "                    labels.append((float(start), float(end), chord))\n",
    "            chord_labels.append(labels)\n",
    "    else:\n",
    "        print(f\"No .lab file found for {track_folder}\")\n",
    "    \n",
    "    return audio_data, sample_rates, chord_labels\n",
    "\n",
    "\n",
    "def load_all_tracks(root_folder):\n",
    "    \"\"\"\n",
    "    Walks through the root folder to load audio and label data for all tracks.\n",
    "    \n",
    "    Arguments:\n",
    "    - root_folder: Path to the dataset's root folder\n",
    "    \n",
    "    Returns:\n",
    "    - dataset: List of dictionaries containing audio, sample rate, and labels for each track\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    # Traverse through each track folder in the root directory\n",
    "    for track_name in os.listdir(root_folder):\n",
    "        track_folder = os.path.join(root_folder, track_name)\n",
    "        if os.path.isdir(track_folder):\n",
    "            # Load audio and labels for the current track folder\n",
    "            audio_data, sample_rates, chord_labels = load_audio_and_labels(track_folder)\n",
    "            dataset.append({\n",
    "                'track_name': track_name,\n",
    "                'audio_data': audio_data, # raw audio data i.e time domain\n",
    "                'sample_rates': sample_rates,\n",
    "                'chord_labels': chord_labels\n",
    "            })\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def load_track(track_folder):\n",
    "    \"\"\"\n",
    "    Loads audio and corresponding label files from a given track folder.\n",
    "    \n",
    "    Arguments:\n",
    "    - track_folder: Path to the track folder containing .wav and .lab files\n",
    "    \n",
    "    Returns:\n",
    "    - audio_data: List of loaded audio arrays\n",
    "    - sample_rates: List of sample rates corresponding to each audio file\n",
    "    - chord_labels: List of chord annotations for each time step\n",
    "    \"\"\"\n",
    "    chord_labels=[]\n",
    "\n",
    "    # Load all .wav files in the track folder\n",
    "    for file_name in os.listdir(track_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(track_folder, file_name)\n",
    "            y, sr = librosa.load(file_path, sr=None)  # Load audio with original sample rate\n",
    "\n",
    "    \n",
    "    # Set the label file path based on the track folder name\n",
    "    track_name = os.path.basename(track_folder)  # Track folder name \n",
    "    label_file_name = f\"{track_name}.lab\"  # Label file name \n",
    "    label_path = os.path.join(track_folder, label_file_name)\n",
    "    \n",
    "    # Load .lab file if it exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = []\n",
    "            for line in f:\n",
    "                # Only take the first three values, ignoring any extra ones\n",
    "                values = line.strip().split()[:3]\n",
    "                if len(values) == 3:  # Ensure we have exactly three values\n",
    "                    start, end, chord = values\n",
    "                    labels.append((float(start), float(end), chord))\n",
    "            chord_labels.append(labels)\n",
    "    else:\n",
    "        print(f\"No .lab file found for {track_folder}\")\n",
    "    \n",
    "    return y, sr, chord_labels\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_all_tracks(root_folder)\n",
    "audio_single, sample_single,chord_single = load_track(track_folder='Data/babyslakh_16k/babyslakh_16k/Track00009')\n",
    "\n",
    "print(audio_single , sample_single, chord_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate spectrogram\n",
    "# suppress overtones\n",
    "# generate chroma vectors\n",
    "# map chord labels with spectrogram\n",
    "# reshape to feed into lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
