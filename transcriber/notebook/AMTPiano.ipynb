{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxCLfnvHZa8W",
    "outputId": "b2bf1e53-ac6f-4283-85a4-bf189b6b5b40"
   },
   "outputs": [],
   "source": [
    "pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVN0CJfWZmNB",
    "outputId": "a791f8b7-abce-4179-f1ed-ded4a5280af0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnZIZFPaZo1D"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTranscriber:\n",
    "    def __init__(self, sr=22050, hop_length=512, n_bins=84, bins_per_octave=12):\n",
    "        self.sr = sr\n",
    "        self.hop_length = hop_length\n",
    "        self.n_bins = n_bins\n",
    "        self.bins_per_octave = bins_per_octave\n",
    "        self.fs = sr / hop_length  # Frame rate for piano roll alignmen\n",
    "        # Calculate sequence_length based on 3 minutes duration\n",
    "        self.standard_duration = 180 \n",
    "        self.sequence_length = int(np.ceil(self.standard_duration * self.fs))  # Number of frames\n",
    "\n",
    "    def process_audio(self, audio_path):\n",
    "        y, _ = librosa.load(audio_path, sr=self.sr, duration=self.standard_duration)\n",
    "        # Compute CQT\n",
    "        C = librosa.cqt(\n",
    "            y,\n",
    "            sr=self.sr,\n",
    "            hop_length=self.hop_length,\n",
    "            n_bins=self.n_bins,\n",
    "            bins_per_octave=self.bins_per_octave\n",
    "        )\n",
    "        # Convert to magnitude and apply log scaling\n",
    "        C_mag = librosa.amplitude_to_db(np.abs(C), ref=np.max)\n",
    "        # Pad or truncate to fixed length\n",
    "        if C_mag.shape[1] < self.sequence_length:\n",
    "            pad_width = ((0, 0), (0, self.sequence_length - C_mag.shape[1]))\n",
    "            C_mag = np.pad(C_mag, pad_width, mode='constant')\n",
    "        else:\n",
    "            C_mag = C_mag[:, :self.sequence_length]\n",
    "        return C_mag\n",
    "\n",
    "    def process_midi(self, midi_path):\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "        end_time = self.standard_duration \n",
    "        # Generate time frames matching the spectrogram\n",
    "        times = np.linspace(0, end_time, self.sequence_length)\n",
    "        piano_roll = midi_data.get_piano_roll(fs=self.fs, times=times)\n",
    "        # Restrict to MIDI note range 21â€“108 (88 keys)\n",
    "        piano_roll = piano_roll[21:109, :] \n",
    "        if piano_roll.shape[1] < self.sequence_length:\n",
    "            pad_width = ((0, 0), (0, self.sequence_length - piano_roll.shape[1]))\n",
    "            piano_roll = np.pad(piano_roll, pad_width, mode='constant')\n",
    "        else:\n",
    "            piano_roll = piano_roll[:, :self.sequence_length]\n",
    "        # Normalize to binary values\n",
    "        piano_roll = (piano_roll > 0).astype(np.float32)\n",
    "        return piano_roll\n",
    "\n",
    "    def create_model(self, input_shape, n_pitches):\n",
    "        # Input layer\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "        # First Convolutional Block\n",
    "        x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 1))(x)  \n",
    "\n",
    "        # Second Convolutional Block\n",
    "        x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        # Reshape for LSTM layer\n",
    "        x = layers.Permute((2, 1, 3))(x)  \n",
    "        new_height = input_shape[0] // 2 \n",
    "\n",
    "        # Reshape to (batch_size, time_steps, new_height * channels)\n",
    "        x = layers.Reshape((x.shape[1], new_height * 64))(x) \n",
    "        \n",
    "        # Bidirectional LSTM layers\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = layers.TimeDistributed(layers.Dense(n_pitches, activation='sigmoid'))(x)\n",
    "\n",
    "        # Create and return the model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def prepare_dataset(self, audio_files, midi_files):\n",
    "        spectrograms = []\n",
    "        piano_rolls = []\n",
    "        for audio_path, midi_path in zip(audio_files, midi_files):\n",
    "            try:\n",
    "                # Process audio\n",
    "                cqt = self.process_audio(audio_path)\n",
    "                # Process MIDI\n",
    "                piano_roll = self.process_midi(midi_path)\n",
    "                spectrograms.append(cqt)\n",
    "                piano_rolls.append(piano_roll)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {audio_path}: {str(e)}\")\n",
    "                continue\n",
    "        # Stack arrays\n",
    "        X = np.stack(spectrograms)\n",
    "        y = np.stack(piano_rolls)\n",
    "        # Add channel dimension for CNN\n",
    "        X = X[..., np.newaxis]  # Shape: (batch_size, n_bins, time_steps, 1)\n",
    "        # Transpose y to have shape (batch_size, time_steps, n_pitches)\n",
    "        y = y.transpose(0, 2, 1)\n",
    "        return X, y\n",
    "\n",
    "def segment_data(X, y, segment_length=512, hop_length=256):\n",
    "    X_segments = []\n",
    "    y_segments = []\n",
    "    for i in range(X.shape[0]):  # Iterate over samples\n",
    "        max_time = X.shape[2]  # Time dimension\n",
    "        for start in range(0, max_time - segment_length + 1, hop_length):\n",
    "            end = start + segment_length\n",
    "            X_segments.append(X[i, :, start:end, :])\n",
    "            y_segments.append(y[i, start:end, :])\n",
    "    X_segments = np.array(X_segments)\n",
    "    y_segments = np.array(y_segments)\n",
    "    return X_segments, y_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kpmzwVlZvmv",
    "outputId": "20fafba0-76e7-4065-99a8-53f0bcab50cf"
   },
   "outputs": [],
   "source": [
    "transcriber = MusicTranscriber()\n",
    "\n",
    "audio_files = [f\"/content/drive/MyDrive/CS 5100 Project/MT Dataset/maestro/Track00{i}.wav\" for i in range(1, 48)]\n",
    "midi_files = [f\"/content/drive/MyDrive/CS 5100 Project/MT Dataset/maestro/Track00{i}.midi\" for i in range(1, 48)]\n",
    "\n",
    "spectrograms, piano_rolls = transcriber.prepare_dataset(audio_files, midi_files)\n",
    "print(f\"Spectrograms shape: {spectrograms.shape}\")\n",
    "print(f\"Piano rolls shape: {piano_rolls.shape}\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(spectrograms, piano_rolls, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWeXgNZXZ0JR",
    "outputId": "79e33504-c768-4c5d-d6cc-1d8fb2084c37"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def focal_loss(alpha=0.35, gamma=3.0):\n",
    "    def focal_loss_with_logits(y_true, y_pred):\n",
    "        # Compute cross entropy loss\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        # Compute the modulating factor\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        modulating_factor = K.pow(1.0 - p_t, gamma)\n",
    "        # Apply alpha weighting\n",
    "        alpha_weight_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        # Compute focal loss\n",
    "        loss = alpha_weight_factor * modulating_factor * bce\n",
    "        return K.mean(loss)\n",
    "    return focal_loss_with_logits\n",
    "\n",
    "\n",
    "class PianoRollPrecision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=0.5, name='piano_roll_precision', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "        false_positives = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "\n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.false_positives.assign_add(false_positives)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0.)\n",
    "        self.false_positives.assign(0.)\n",
    "\n",
    "class PianoRollRecall(tf.keras.metrics.Metric):\n",
    "    def __init__(self,threshold=0.5, name='piano_roll_recall', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "        false_negatives = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "\n",
    "        self.true_positives.assign_add(true_positives)\n",
    "        self.false_negatives.assign_add(false_negatives)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0.)\n",
    "        self.false_negatives.assign(0.)\n",
    "\n",
    "class PianoRollF1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='piano_roll_f1', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = PianoRollPrecision()\n",
    "        self.recall = PianoRollRecall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()\n",
    "\n",
    "\n",
    "# Segment the data\n",
    "segment_length = 512\n",
    "hop_length = 256\n",
    "X_train_seg, y_train_seg = segment_data(X_train, y_train, segment_length, hop_length)\n",
    "X_val_seg, y_val_seg = segment_data(X_val, y_val, segment_length, hop_length)\n",
    "\n",
    "print(f\"Segmented X_train shape: {X_train_seg.shape}\")\n",
    "print(f\"Segmented y_train shape: {y_train_seg.shape}\")\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train_seg.shape[1:]  # (n_bins, segment_length, 1)\n",
    "n_pitches = y_train_seg.shape[2]     # Should be 88 (number of pitches)\n",
    "\n",
    "model = transcriber.create_model(input_shape, n_pitches)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=focal_loss(alpha=0.35, gamma=4.0), metrics=[PianoRollPrecision(0.4), PianoRollRecall(0.4), PianoRollF1Score()])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seg, y_train_seg,\n",
    "    validation_data=(X_val_seg, y_val_seg),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QH3bj4c7X8T",
    "outputId": "ee4e81c6-ca93-4764-ad08-baf034358bd1"
   },
   "outputs": [],
   "source": [
    "model.save('piano_transcriberF1.h5')\n",
    "model.save('piano_transcriberF1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNWbScPGZ04Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_sparse_piano_roll(y_true, y_pred, epsilon=1e-7):\n",
    "    # Flatten y_true and y_pred to 1D arrays\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "\n",
    "    # Identify active regions (where either y_true or y_pred is positive)\n",
    "    active_regions = (y_true_flat > 0) | (y_pred_flat > 0)\n",
    "\n",
    "    # Calculate standard metrics on active regions\n",
    "    precision = precision_score(y_true_flat[active_regions], y_pred_flat[active_regions], zero_division=0)\n",
    "    recall = recall_score(y_true_flat[active_regions], y_pred_flat[active_regions], zero_division=0)\n",
    "    f1 = f1_score(y_true_flat[active_regions], y_pred_flat[active_regions], zero_division=0)\n",
    "\n",
    "    # Note-wise accuracy (focusing on active notes)\n",
    "    true_positives = np.sum((y_true_flat == 1) & (y_pred_flat == 1))\n",
    "    false_positives = np.sum((y_true_flat == 0) & (y_pred_flat == 1))\n",
    "    false_negatives = np.sum((y_true_flat == 1) & (y_pred_flat == 0))\n",
    "\n",
    "    note_precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "    note_recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "    note_f1 = 2 * (note_precision * note_recall) / (note_precision + note_recall + epsilon)\n",
    "\n",
    "    return {\n",
    "        'active_precision': precision,\n",
    "        'active_recall': recall,\n",
    "        'active_f1': f1,\n",
    "        'note_precision': note_precision,\n",
    "        'note_recall': note_recall,\n",
    "        'note_f1': note_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QDa4pezAUzp"
   },
   "outputs": [],
   "source": [
    "def evaluate_framewise_piano_roll(y_true, y_pred, epsilon=1e-7):\n",
    "    # Flatten y_true and y_pred to 1D arrays\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "\n",
    "    # Calculate standard metrics for the entire dataset and not just active regions\n",
    "    precision = precision_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    recall = recall_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    f1 = f1_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'frame_precision': precision,\n",
    "        'frame_recall': recall,\n",
    "        'frame_f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MP-xcIvZ2nI",
    "outputId": "48ac5ba8-259d-42d4-dfcb-1082bc2d0837"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val_seg)  \n",
    "\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions > threshold).astype(np.float32)\n",
    "\n",
    "def evaluate_all_metrics(y_true, y_pred, epsilon=1e-7):\n",
    "    # Flatten y_true and y_pred\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "\n",
    "    # Framewise metrics\n",
    "    frame_metrics = evaluate_framewise_piano_roll(y_true, y_pred)\n",
    "\n",
    "    # Note-wise metrics\n",
    "    note_metrics = evaluate_sparse_piano_roll(y_true, y_pred, epsilon)\n",
    "\n",
    "    return {**frame_metrics, **note_metrics}\n",
    "\n",
    "\n",
    "metrics = evaluate_all_metrics(y_val_seg, binary_predictions)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "r57vtuRUZ4Y-",
    "outputId": "4d0eb0c7-a532-4eeb-e07b-2e7f46e8531c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_comparison(y_true, y_pred, sample_idx=0, start_idx=0, length=100):\n",
    "    y_true_sample = y_true[sample_idx]  \n",
    "    y_pred_sample = y_pred[sample_idx]\n",
    "\n",
    "    # Select the segment\n",
    "    y_true_segment = y_true_sample[start_idx:start_idx+length]\n",
    "    y_pred_segment = y_pred_sample[start_idx:start_idx+length]\n",
    "\n",
    "    # Compute the difference\n",
    "    difference = y_true_segment - y_pred_segment\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "    sns.heatmap(y_true_segment.T, ax=axes[0], cmap='Blues', cbar=False)\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].set_ylabel('Pitch')\n",
    "\n",
    "    sns.heatmap(y_pred_segment.T, ax=axes[1], cmap='Blues', cbar=False)\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[1].set_ylabel('Pitch')\n",
    "\n",
    "    sns.heatmap(difference.T, ax=axes[2], cmap='RdBu_r', center=0, cbar=False)\n",
    "    axes[2].set_title('Difference (Blue: False Negative, Red: False Positive)')\n",
    "    axes[2].set_ylabel('Pitch')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_comparison(y_val_seg, binary_predictions, sample_idx=0, start_idx=0, length=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE MIDI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VlnUEIEaIvl"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def segment_features(features, segment_length=512, hop_length=256):\n",
    "#     segments = []\n",
    "#     max_time = features.shape[1] \n",
    "#     for start in range(0, max_time - segment_length + 1, hop_length):\n",
    "#         end = start + segment_length\n",
    "#         segments.append(features[:, start:end, :])  \n",
    "#     return np.array(segments)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def piano_roll_to_midi(piano_roll, fs=43.06, program=0, velocity=100):\n",
    "#     midi = pretty_midi.PrettyMIDI()\n",
    "#     instrument = pretty_midi.Instrument(program=program)\n",
    "    \n",
    "#     time_per_frame = 1.0 / fs\n",
    "\n",
    "#     for pitch in range(piano_roll.shape[1]):\n",
    "#         # Find all contiguous segments of 'on' notes\n",
    "#         active_times = np.where(piano_roll[:, pitch] > 0.5)[0]\n",
    "#         if len(active_times) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         # Group contiguous times\n",
    "#         note_start = active_times[0]\n",
    "#         for i in range(1, len(active_times)):\n",
    "#             if active_times[i] != active_times[i - 1] + 1:\n",
    "#                 # Note off\n",
    "#                 note_end = active_times[i - 1]\n",
    "#                 start_time = note_start * time_per_frame\n",
    "#                 end_time = (note_end + 1) * time_per_frame\n",
    "#                 note = pretty_midi.Note(velocity=velocity, pitch=pitch + 21, start=start_time, end=end_time)\n",
    "#                 instrument.notes.append(note)\n",
    "#                 # Update note start\n",
    "#                 note_start = active_times[i]\n",
    "        \n",
    "#         # Add the final note\n",
    "#         note_end = active_times[-1]\n",
    "#         start_time = note_start * time_per_frame\n",
    "#         end_time = (note_end + 1) * time_per_frame\n",
    "#         note = pretty_midi.Note(velocity=velocity, pitch=pitch + 21, start=start_time, end=end_time)\n",
    "#         instrument.notes.append(note)\n",
    "    \n",
    "#     midi.instruments.append(instrument)\n",
    "    \n",
    "#     return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import IPython.display as ipd\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import tensorflow as tf\n",
    "# import pretty_midi\n",
    "\n",
    "# audio_file = \"Track002.wav\"\n",
    "# ipd.display(ipd.Audio(filename=audio_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transcriber = MusicTranscriber()\n",
    "# cqt = transcriber.process_audio(audio_file)  \n",
    "# cqt = np.expand_dims(cqt, axis=-1) \n",
    "\n",
    "# # Segment the input into slices of length 512\n",
    "# segments = segment_features(cqt, segment_length=512, hop_length=256) \n",
    "\n",
    "# model_path = 'piano_transcriberF1.keras'\n",
    "# model = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "\n",
    "# predictions = model.predict(segments)  \n",
    "\n",
    "# piano_roll = np.concatenate(predictions, axis=0)  \n",
    "\n",
    "# midi = piano_roll_to_midi(piano_roll, fs=43.06)\n",
    "# midi.write('output.midi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pretty_midi\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def display_piano_roll(midi_file, fs=100):\n",
    "\n",
    "#     midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    \n",
    "#     piano_roll = midi_data.get_piano_roll(fs=fs)\n",
    "\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     plt.imshow(\n",
    "#         piano_roll[21:109],  \n",
    "#         aspect='auto',\n",
    "#         origin='lower',\n",
    "#         cmap='gray_r',\n",
    "#         interpolation='nearest',\n",
    "#     )\n",
    "#     plt.title('Piano Roll')\n",
    "#     plt.xlabel('Time (frames)')\n",
    "#     plt.ylabel('Pitch (MIDI Notes)')\n",
    "#     plt.colorbar(label='Velocity')\n",
    "#     plt.show()\n",
    "\n",
    "# midi_file = 'output.midi'  \n",
    "# display_piano_roll(midi_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
